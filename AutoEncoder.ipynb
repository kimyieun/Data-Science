{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimyieun/Data-Science/blob/master/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbzrViADzGvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4d98bfc5-69d2-4b71-c53e-09caba22316f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num = 100000;\n",
        "X = [[n, n, n] for n in range(num)];\n",
        "X = torch.tensor(X).float()\n",
        "X"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
              "        [2.0000e+00, 2.0000e+00, 2.0000e+00],\n",
              "        ...,\n",
              "        [9.9997e+04, 9.9997e+04, 9.9997e+04],\n",
              "        [9.9998e+04, 9.9998e+04, 9.9998e+04],\n",
              "        [9.9999e+04, 9.9999e+04, 9.9999e+04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk_qdkNJzNRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 3\n",
        "output_size = 3\n",
        "hidden_size = 1io;\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Linear(input_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #x = F.leaky_relu(self.encoder(x))\n",
        "        x = self.encoder(x)\n",
        "        out = self.decoder(x)\n",
        "        #out = F.leaky_relu(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06qQaf3gzPiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2e52ca7-1437-4e91-8aa7-f9ec3ff1b856"
      },
      "source": [
        "autoencoder = Autoencoder(input_size, hidden_size, output_size)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(autoencoder.parameters(), lr=0.0000001, weight_decay=1000000000)\n",
        "\n",
        "epoch = 6\n",
        "for t in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    print(autoencoder.encoder.weight)\n",
        "    output = autoencoder(X.float())\n",
        "    loss = loss_function(output, X.float())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(output)\n",
        "\n",
        "    if t % 1000 == 0:\n",
        "        print(output)\n",
        "        print(loss.data.numpy())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1372, -0.4422, -0.4510]], requires_grad=True)\n",
            "tensor([[ 3.3200e-01,  6.7145e-01, -7.1224e-01],\n",
            "        [ 3.9931e-01,  1.1514e+00, -9.3024e-01],\n",
            "        [ 4.6661e-01,  1.6313e+00, -1.1482e+00],\n",
            "        ...,\n",
            "        [ 6.7306e+03,  4.7993e+04, -2.1800e+04],\n",
            "        [ 6.7307e+03,  4.7993e+04, -2.1801e+04],\n",
            "        [ 6.7308e+03,  4.7994e+04, -2.1801e+04]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3200e-01,  6.7145e-01, -7.1224e-01],\n",
            "        [ 3.9931e-01,  1.1514e+00, -9.3024e-01],\n",
            "        [ 4.6661e-01,  1.6313e+00, -1.1482e+00],\n",
            "        ...,\n",
            "        [ 6.7306e+03,  4.7993e+04, -2.1800e+04],\n",
            "        [ 6.7307e+03,  4.7993e+04, -2.1801e+04],\n",
            "        [ 6.7308e+03,  4.7994e+04, -2.1801e+04]], grad_fn=<AddmmBackward>)\n",
            "2915431000.0\n",
            "Parameter containing:\n",
            "tensor([[ 3.4821, 33.6781, 34.5447]], requires_grad=True)\n",
            "tensor([[-1.4820e+03, -5.7395e+02, -2.0298e+03],\n",
            "        [-1.6332e+04, -5.8059e+03, -2.3529e+04],\n",
            "        [-3.1181e+04, -1.1038e+04, -4.5029e+04],\n",
            "        ...,\n",
            "        [-1.4849e+09, -5.2318e+08, -2.1499e+09],\n",
            "        [-1.4849e+09, -5.2319e+08, -2.1499e+09],\n",
            "        [-1.4849e+09, -5.2319e+08, -2.1499e+09]], grad_fn=<AddmmBackward>)\n",
            "Parameter containing:\n",
            "tensor([[-2.2008e+09, -2.2008e+09, -2.2008e+09]], requires_grad=True)\n",
            "tensor([[-7.9765e+12, -2.8107e+12, -1.1549e+13],\n",
            "        [-1.5625e+18, -5.5059e+17, -2.2622e+18],\n",
            "        [-3.1250e+18, -1.1012e+18, -4.5244e+18],\n",
            "        ...,\n",
            "        [-1.5624e+23, -5.5057e+22, -2.2621e+23],\n",
            "        [-1.5625e+23, -5.5058e+22, -2.2622e+23],\n",
            "        [-1.5625e+23, -5.5058e+22, -2.2622e+23]], grad_fn=<AddmmBackward>)\n",
            "Parameter containing:\n",
            "tensor([[2.6461e+29, 2.6461e+29, 2.6461e+29]], requires_grad=True)\n",
            "tensor([[-inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf],\n",
            "        ...,\n",
            "        [-inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf]], grad_fn=<AddmmBackward>)\n",
            "Parameter containing:\n",
            "tensor([[nan, nan, nan]], requires_grad=True)\n",
            "tensor([[nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan]], grad_fn=<AddmmBackward>)\n",
            "Parameter containing:\n",
            "tensor([[nan, nan, nan]], requires_grad=True)\n",
            "tensor([[nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan],\n",
            "        [nan, nan, nan]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4a2OxYIzrxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}